# main.py
import streamlit as st
import requests
import tiktoken
import os

from loguru import logger
from googleapiclient.discovery import build
from PyPDF2 import PdfReader
from langchain.chains import ConversationalRetrievalChain
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import PyPDFLoader, Docx2txtLoader, UnstructuredPowerPointLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.memory import ConversationBufferMemory
from langchain.vectorstores import FAISS
from langchain.callbacks import get_openai_callback
import docx
from io import BytesIO


# --------------------------
# ê¸°ëŠ¥ í•¨ìˆ˜
# --------------------------
def tiktoken_len(text):
    tokenizer = tiktoken.get_encoding("cl100k_base")
    tokens = tokenizer.encode(text)
    return len(tokens)

def get_text(docs):
    doc_list = []
    
    for doc in docs:
        file_name = doc.name
        with open(file_name, "wb") as file:
            file.write(doc.getvalue())
            logger.info(f"Uploaded {file_name}")
            
        if '.pdf' in file_name:
            loader = PyPDFLoader(file_name)
        elif '.docx' in file_name:
            loader = Docx2txtLoader(file_name)
        elif '.pptx' in file_name:
            loader = UnstructuredPowerPointLoader(file_name)
        else:
            continue
            
        documents = loader.load_and_split()
        doc_list.extend(documents)
        
    return doc_list

# í…ìŠ¤íŠ¸ ì²­í‚¹ í•¨ìˆ˜
def get_text_chunks(text):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=900,
        chunk_overlap=100,
        length_function=tiktoken_len
    )
    chunks = text_splitter.split_documents(text)
    return chunks

# ë²¡í„° ìŠ¤í† ì–´ ìƒì„± í•¨ìˆ˜
def get_vectorstore(text_chunks):
    embeddings = HuggingFaceEmbeddings(
        model_name="jhgan/ko-sroberta-multitask",
        model_kwargs={'device': 'mps'},
        encode_kwargs={'normalize_embeddings': True}
    )  
    vectordb = FAISS.from_documents(text_chunks, embeddings)
    return vectordb

# ëŒ€í™” ì²´ì¸ ìƒì„± í•¨ìˆ˜
def get_conversation_chain(vectorstore, openai_api_key, model_name):
    llm = ChatOpenAI(openai_api_key=openai_api_key, model_name=model_name, temperature=0)
    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm, 
        chain_type="stuff", 
        retriever=vectorstore.as_retriever(search_type='mmr', verbose=True), 
        memory=ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer'),
        get_chat_history=lambda h: h,
        return_source_documents=True,
        verbose=True
    )
    return conversation_chain

# ì±„íŒ… ê¸°ë¡ ì €ì¥ í•¨ìˆ˜
def save_chat_history(title=""):
    if 'messages' in st.session_state and len(st.session_state.messages) > 0:
        if not os.path.exists('chat_history'):
            os.makedirs('chat_history')
        
        if not title:
            title = "chat_history"
        
        safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '_', '-')).rstrip()
        filename = f"{safe_title}.txt"
        filepath = os.path.join('chat_history', filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            for msg in st.session_state.messages:
                f.write(f"[{msg['role'].upper()}] {msg['content']}\n")
        
        st.success(f"âœ… ì±„íŒ… ê¸°ë¡ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}")
        return True
    else:
        st.warning("ì €ì¥í•  ì±„íŒ… ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
# ì €ì¥ëœ ì±„íŒ… ê¸°ë¡ í‘œì‹œ í•¨ìˆ˜
def display_saved_chats():
    st.subheader("ğŸ“ ì €ì¥ëœ ì±„íŒ… ê¸°ë¡")
    
    if not os.path.exists('chat_history'):
        st.info("ì±„íŒ… ê¸°ë¡ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return []
        
    files = [f for f in os.listdir('chat_history') if f.endswith('.txt')]
    
    if not files:
        st.info("ì•„ì§ ì €ì¥ëœ ì±„íŒ… ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        return []
        
    cols = st.columns(3)
    for idx, file in enumerate(files):
        with cols[idx%3]:
            with open(os.path.join('chat_history', file), 'r', encoding='utf-8') as f:
                content = f.read()
            st.download_button(
                label=f"ğŸ“„ {file}",
                data=content,
                file_name=file,
                mime="text/plain"
            )
    
    return files

# ì±„íŒ… ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
def load_chat_history(filename):
    messages = []
    file_path = os.path.join('chat_history', filename)
    
    if not os.path.exists(file_path):
        st.error(f"{filename} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
        
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.startswith("[USER]"):
                messages.append({"role": "user", "content": line[len("[USER] "):].strip()})
            elif line.startswith("[ASSISTANT]"):
                messages.append({"role": "assistant", "content": line[len("[ASSISTANT] "):].strip()})
                
    if messages:
        st.session_state['messages'] = messages
        st.success(f"âœ… {filename} ì±„íŒ… ê¸°ë¡ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        return True
    
    st.warning(f"{filename} íŒŒì¼ì—ì„œ ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return False    

def process_file(uploaded_file):
    """PDF/DOCX/TXT íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    if uploaded_file.type == "application/pdf":
        reader = PdfReader(uploaded_file)
        return "\n".join(page.extract_text() or "" for page in reader.pages)
    if uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        doc = docx.Document(uploaded_file)
        return "\n".join(p.text for p in doc.paragraphs)
    if uploaded_file.type == "text/plain":
        return uploaded_file.read().decode("utf-8")
    return ""

def google_search(query, api_key, cse_id, num=5):
    """Google Custom Search API í˜¸ì¶œ"""
    service = build("customsearch", "v1", developerKey=api_key)
    return service.cse().list(q=query, cx=cse_id, num=num).execute().get("items", [])

def generate_answer(messages, openai_key, model="gpt-4"):
    """OpenAI Chat Completion í˜¸ì¶œ"""
    headers = {"Authorization": f"Bearer {openai_key}"}
    payload = {"model": model, "messages": messages}
    resp = requests.post(
        "https://api.openai.com/v1/chat/completions",
        headers=headers, json=payload
    )
    resp.raise_for_status()
    return resp.json()["choices"][0]["message"]["content"]



def setup_sidebar():
    """ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë“œÂ·API í‚¤Â·íŒŒì¼ ì—…ë¡œë“œ ì„¤ì •"""
    st.sidebar.header("âš™ï¸ Config")
    st.sidebar.image(
        "./36logo.png",
        use_container_width=True
    )
    
    with st.sidebar.expander("ğŸ¤ª Contributors", expanded=False):
        st.markdown("""
                    ## Leader: ğŸ˜ë°•ê¸°í˜¸
                    ### Member1 : ğŸ¤‘ê¹€íƒœìœ¤
                    ### Memeber2 : ğŸ‘·â€â™‚ï¸ë°•í˜„ì‹  """)
        
    
    st.sidebar.markdown("""\nI've been workin like a dog""")
    st.sidebar.divider()
    mode = st.sidebar.radio(
        "Mode Select",
        ["Web Searching Mode", "Uploaded File + Searching Mode", "Answer Based on Uploaded File Mode"]
    )
    
    st.sidebar.divider()
    
    # ì±„íŒ… ê¸°ë¡ ê´€ë¦¬ ì„¹ì…˜ - ì‚¬ì´ë“œë°”ë¡œ ëª¨ë‘ í†µí•©
    st.sidebar.subheader("ğŸ’¬ Chat History Manager")
    
    # ì±„íŒ… ì €ì¥ ê¸°ëŠ¥
    with st.sidebar.expander("Save Current Chat", expanded=False):
        chat_title = st.text_input("Chat Title", "", key="save_chat_title")
        if st.button("Save Chat History"):
            save_chat_history(chat_title)
    
    # ì±„íŒ… ë¶ˆëŸ¬ì˜¤ê¸° ê¸°ëŠ¥
    with st.sidebar.expander("Load Chat History", expanded=False):
        if not os.path.exists('chat_history'):
            st.info("ì±„íŒ… ê¸°ë¡ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            files = [f for f in os.listdir('chat_history') if f.endswith('.txt')]
            if not files:
                st.info("ì•„ì§ ì €ì¥ëœ ì±„íŒ… ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                selected_file = st.selectbox("Select saved chat", [""] + files)
                if st.button("Load Selected Chat") and selected_file:
                    load_chat_history(selected_file)
    
    # ì €ì¥ëœ ì±„íŒ… ê¸°ë¡ í‘œì‹œ ê¸°ëŠ¥
    with st.sidebar.expander("Browse Saved Chats", expanded=False):
        if os.path.exists('chat_history'):
            files = [f for f in os.listdir('chat_history') if f.endswith('.txt')]
            if files:
                for file in files:
                    with open(os.path.join('chat_history', file), 'r', encoding='utf-8') as f:
                        content = f.read()
                    st.download_button(
                        label=f"ğŸ“„ {file}",
                        data=content,
                        file_name=file,
                        mime="text/plain"
                    )
            else:
                st.info("ì•„ì§ ì €ì¥ëœ ì±„íŒ… ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ì±„íŒ… ê¸°ë¡ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    st.sidebar.divider()
    
    # API í‚¤ ë° íŒŒì¼ ì—…ë¡œë“œ ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
    openai_key = st.sidebar.text_input("OpenAI API í‚¤", type="password")
    google_key = google_cse = None
    if "Searching" in mode:
        google_key = st.sidebar.text_input("Google API í‚¤", type="password")
        google_cse = st.sidebar.text_input("Google CSE ID", type="password")
    uploader = st.sidebar.file_uploader(
        "íŒŒì¼ ì—…ë¡œë“œ (pdf/docx/txt)", type=["pdf", "docx", "txt"]
    )
    if uploader:
        st.session_state.file_content = process_file(uploader)
        st.sidebar.success("íŒŒì¼ ë¶„ì„ ì™„ë£Œ!")

    return mode, openai_key, google_key, google_cse


# --------------------------
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# --------------------------
def main():
    st.set_page_config(
        page_title="Help Me Please....",
        page_icon="ğŸ”",
        layout="centered",
        initial_sidebar_state="auto"
    )
    # ì„¸ì…˜ ì´ˆê¸°í™”
    if "chat_started" not in st.session_state:
        st.session_state.chat_started = False
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "file_content" not in st.session_state:
        st.session_state.file_content = ""
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = None
        
    placeholder = st.empty()

    # ì´ˆê¸° í™”ë©´
    if not st.session_state.chat_started:
        with placeholder.container():
            st.image("36logo.png", width=50)
            st.markdown("## ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?")
            setup_sidebar()
            col1, col2, col3 = st.columns([1, 4, 1])
            with col2:
                q = st.text_input(
                    "", placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”", key="init_q"
                )
                if q:
                    st.session_state.messages.append({
                        "role": "user", "content": q
                    })
                    st.session_state.chat_started = True
                    # ì´ˆê¸° í™”ë©´ ì œê±° í›„ ì¬ì‹¤í–‰
                    placeholder.empty()
                    st.rerun()
    else:
        # ì´ˆê¸° í™”ë©´ placeholder ì œê±°
        placeholder.empty()

        # ì‚¬ì´ë“œë°” ì„¤ì •
        mode, openai_key, google_key, google_cse = setup_sidebar()
        st.title("ğŸ” AI ê²€ìƒ‰ ì—”ì§„")

        # ì²« ì¸ì‚¬
        if (len(st.session_state.messages) == 1 
            and st.session_state.messages[0]["role"] == "user"):
            st.session_state.messages.insert(0, {
                "role": "assistant",
                "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”."
            })

        # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
        for msg in st.session_state.messages:
            if msg["role"] == "user":
                with st.chat_message("user"):
                    st.markdown(msg["content"])
            else:
                with st.chat_message("assistant"):
                    st.markdown(msg["content"])

        # ì¶”ê°€ ì§ˆë¬¸ ì…ë ¥
        prompt = st.chat_input("ì¶”ê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
        if prompt:
            # API í‚¤ ê²€ì¦
            if not openai_key or ("ê²€ìƒ‰" in mode and (not google_key or not google_cse)):
                st.sidebar.error("í•„ìˆ˜ API í‚¤ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”")
            else:
                # ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡
                st.session_state.messages.append({
                    "role": "user", "content": prompt
                })

                # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
                context = ""
                if "File" in mode and st.session_state.file_content:
                    context += f"íŒŒì¼ ë‚´ìš©:\n{st.session_state.file_content}\n\n"
                sources = []
                if "Searching" in mode:
                    results = google_search(prompt, google_key, google_cse, num=3)
                    for i, item in enumerate(results, 1):
                        context += f"[{i}] {item['title']}\n{item.get('snippet','')}\n\n"
                        sources.append((item['title'], item['link']))

                # OpenAI í˜¸ì¶œ
                messages = [
                    {"role": "system", "content": "ìµœëŒ€í•œ ì¹œê·¼í•˜ê²Œ ëŒ€ë‹µí•˜ì„¸ìš”."},
                    {"role": "user", "content": f"{prompt}\n\n{context}"}
                ]
                answer = generate_answer(messages, openai_key)
                st.session_state.messages.append({
                    "role": "assistant", "content": answer
                })

                # í™”ë©´ ê°±ì‹ 
                st.rerun()

if __name__ == "__main__":
    main()

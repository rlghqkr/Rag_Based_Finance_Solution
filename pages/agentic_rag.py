import os
import streamlit as st
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.memory import ConversationBufferMemory
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import PyPDFLoader, Docx2txtLoader, UnstructuredPowerPointLoader
from langchain.chains import RetrievalQA
import yfinance as yf
import tempfile, uuid, shutil, time
import matplotlib.pyplot as plt
import pandas as pd
import io
import base64
import re
import json

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# --- ì„¤ë¬¸ UI ---
def portfolio_survey():
    st.markdown("### ğŸ“ ë‚´ ì£¼ì‹ í˜„í™© ì„¤ë¬¸")
    sector = st.selectbox("ì„ í˜¸ ì—…ì¢…", ["IT/í…Œí¬", "í—¬ìŠ¤ì¼€ì–´", "ê¸ˆìœµ", "ì—ë„ˆì§€", "ì†Œë¹„ì¬", "ê¸°íƒ€"])
    risk = st.radio("íˆ¬ì ì„±í–¥", ["ì•ˆì •í˜•", "ì¤‘ë¦½í˜•", "ê³µê²©í˜•"])
    period = st.selectbox("ì˜ˆìƒ íˆ¬ì ê¸°ê°„", ["1ë…„ ë¯¸ë§Œ", "1~3ë…„", "3~5ë…„", "5ë…„ ì´ìƒ"])
    region = st.multiselect("ê´€ì‹¬ êµ­ê°€", ["í•œêµ­", "ë¯¸êµ­", "ì¤‘êµ­", "ì¼ë³¸", "ìœ ëŸ½", "ê¸°íƒ€"], default=["í•œêµ­","ë¯¸êµ­"])
    tickers = st.text_input("ì£¼ìš” íˆ¬ì ì¢…ëª©(í‹°ì»¤, ì½¤ë§ˆë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ: AAPL, TSLA, 005930.KS")
    amount = st.slider("ì´ íˆ¬ìê¸ˆ(ë§Œì›)", 100, 10000, 1000, 100)
    return {
        "sector": sector,
        "risk": risk,
        "period": period,
        "region": region,
        "tickers": tickers,
        "amount": amount
    }

def get_portfolio_description(survey):
    desc = (
        f"ì„ í˜¸ ì—…ì¢…: {survey['sector']}\n"
        f"íˆ¬ì ì„±í–¥: {survey['risk']}\n"
        f"íˆ¬ì ê¸°ê°„: {survey['period']}\n"
        f"ê´€ì‹¬ êµ­ê°€: {', '.join(survey['region'])}\n"
        f"ì£¼ìš” íˆ¬ì ì¢…ëª©(í‹°ì»¤): {survey['tickers']}\n"
        f"ì´ íˆ¬ìê¸ˆ: {survey['amount']}ë§Œì›"
    )
    return desc

# --- yfinance ì°¨íŠ¸/ì •ë³´ Tool ---
def get_stock_info_and_plot(ticker: str):
    try:
        info = yf.Ticker(ticker).info
        name = info.get('longName', ticker)
        df = yf.Ticker(ticker).history(period='6mo')
        if df.empty:
            return f"'{ticker}' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        fig, ax = plt.subplots(figsize=(6,3))
        ax.plot(df.index, df['Close'], label='ì¢…ê°€')
        ax.set_title(name)
        ax.legend()
        buf = io.BytesIO()
        plt.savefig(buf, format="png")
        plt.close(fig)
        buf.seek(0)
        img_base64 = base64.b64encode(buf.read()).decode("utf-8")
        latest = df['Close'].iloc[-1]
        summary = info.get('longBusinessSummary', '')
        return f"![{name}](data:image/png;base64,{img_base64})\n\n**í˜„ì¬ê°€:** {latest:,.2f}\n\n{summary}"
    except Exception as e:
        return f"{ticker} ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}"

# --- ë¬¸ì„œ ì—…ë¡œë“œ ë° ë²¡í„°ìŠ¤í† ì–´ ---
def load_documents(files):
    temp_dir = tempfile.mkdtemp(prefix="st_upload_")
    docs = []
    try:
        for f in files:
            path = os.path.join(temp_dir, f"{uuid.uuid4().hex}_{f.name}")
            with open(path, "wb") as fp:
                fp.write(f.getvalue())
            low = path.lower()
            if low.endswith(".pdf"):
                docs += PyPDFLoader(path).load_and_split()
            elif low.endswith(".docx"):
                docs += Docx2txtLoader(path).load()
            elif low.endswith(".pptx"):
                docs += UnstructuredPowerPointLoader(path).load()
    finally:
        shutil.rmtree(temp_dir, ignore_errors=True)
    return docs

@st.cache_resource(ttl="1h")
def get_vectorstore(files):
    if not files:
        return None
    docs = load_documents(files)
    splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=400)
    chunks = splitter.split_documents(docs)
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    vs = FAISS.from_documents(chunks, embeddings)
    return vs

def rag_search(query: str, vectorstore, llm) -> str:
    if not vectorstore:
        return "ì°¸ê³  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
    retriever = vectorstore.as_retriever(search_kwargs={"k":3})
    chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=False,
    )
    return chain.run(query)

# --- í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ Tool ---
def analyze_portfolio(survey, llm) -> str:
    desc = get_portfolio_description(survey)
    prompt = f"""ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ì£¼ì‹ í¬íŠ¸í´ë¦¬ì˜¤ ì„¤ë¬¸ ê²°ê³¼ì…ë‹ˆë‹¤.
{desc}
ì´ ì¡°ê±´ì— ë§ëŠ” ìµœì ì˜ í¬íŠ¸í´ë¦¬ì˜¤(ì¢…ëª©, ë¹„ì¤‘, êµ­ê°€, ì—…ì¢… ë“±)ë¥¼ ì¶”ì²œí•˜ê³ ,
ì¶”ì²œ ì´ìœ , ë¦¬ìŠ¤í¬ ìš”ì¸, ë¶„ì‚° íš¨ê³¼, ì—…ì¢…ë³„ ì „ë§ë„ ìì„¸íˆ ì„¤ëª…í•´ì¤˜.
í¬íŠ¸í´ë¦¬ì˜¤ëŠ” ë§ˆí¬ë‹¤ìš´ í‘œë¡œ, ì„¤ëª…ì€ ìì—°ì–´ë¡œ ì¶œë ¥í•´ì¤˜. JSON, ë¦¬ìŠ¤íŠ¸, ì½”ë“œë¸”ë¡ ë“±ì€ ì¶œë ¥í•˜ì§€ ë§ˆ."""
    return llm.predict(prompt)

# --- ë§ˆí¬ë‹¤ìš´ í‘œ íŒŒì‹± ë° íŒŒì´ì°¨íŠ¸ ì‹œê°í™” ---
def extract_markdown_table(answer):
    # ë§ˆí¬ë‹¤ìš´ í‘œ ì¶”ì¶œ (|ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ì´ ìˆìœ¼ë©´)
    lines = answer.splitlines()
    table_lines = []
    in_table = False
    for line in lines:
        if "|" in line:
            table_lines.append(line)
            in_table = True
        elif in_table and line.strip() == "":
            break
    if not table_lines:
        return None, answer
    table_md = "\n".join(table_lines)
    pre = answer.split(table_md)[0].strip()
    post = answer.split(table_md)[1].strip() if table_md in answer else ""
    return table_md, pre + "\n\n" + post

def plot_portfolio_pie_from_md(table_md):
    import pandas as pd
    from io import StringIO

    try:
        # ë§ˆí¬ë‹¤ìš´ í‘œì—ì„œ êµ¬ë¶„ì„ (---) í–‰ì„ ì œê±°
        lines = table_md.strip().splitlines()
        # ì²« ì¤„: í—¤ë”, ë‘ ë²ˆì§¸ ì¤„: êµ¬ë¶„ì„ (---), ë‚˜ë¨¸ì§€: ë°ì´í„°
        if len(lines) >= 2 and set(lines[1].replace('|', '').strip()) <= {'-'}:
            lines = [lines[0]] + lines[2:]
        # í˜¹ì‹œ ì¤‘ê°„ì— ë˜ ---ê°€ ìˆìœ¼ë©´ ëª¨ë‘ ì œê±°
        clean_lines = [line for line in lines if not (set(line.replace('|', '').strip()) <= {'-'})]
        clean_table_md = "\n".join(clean_lines)

        # DataFrame ë³€í™˜
        df = pd.read_csv(StringIO(clean_table_md), sep="|", engine="python")
        # ì²« ë²ˆì§¸ ë¹ˆ ì»¬ëŸ¼ ìë™ ì œê±° (ë§ˆí¬ë‹¤ìš´ í‘œ íŠ¹ì„±)
        df = df.loc[:, ~df.columns.str.strip().eq("")]
        df = df.reset_index(drop=True)

        # weight ë˜ëŠ” ë¹„ì¤‘ ì»¬ëŸ¼ ì°¾ê¸°
        weight_col = None
        for c in df.columns:
            if "weight" in c.lower() or "ë¹„ì¤‘" in c:
                weight_col = c
        if not weight_col:
            st.warning("ë¹„ì¤‘(weight) ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        labels = df[df.columns[0]].astype(str)
        sizes = df[weight_col].astype(float)
        fig, ax = plt.subplots(figsize=(5,5))
        ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
        ax.axis('equal')
        st.pyplot(fig)
    except Exception as e:
        st.warning("í¬íŠ¸í´ë¦¬ì˜¤ íŒŒì‹±/ì‹œê°í™” ì‹¤íŒ¨: " + str(e))

def render_agentic_rag_tab():
    st.header("ğŸ¤– Agentic RAG: ê°œì¸í™” í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œ")
    survey = portfolio_survey()

    # ë¬¸ì„œ ì—…ë¡œë“œ
    uploaded_docs = st.file_uploader(
        "ì‹œì¥ë¶„ì„ PDF/DOCX/PPTX ì—…ë¡œë“œ (ì„ íƒ)", type=["pdf","docx","pptx"], accept_multiple_files=True
    )
    vectorstore = get_vectorstore(uploaded_docs) if uploaded_docs else None

    # GPT-4.0 LLM ê³ ì •
    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name="gpt-4", temperature=0.3)

    # Tool ì •ì˜ (ì˜ë¬¸ëª… í•„ìˆ˜)
    tools = [
        Tool(
            name="portfolio_analysis",
            func=lambda x: analyze_portfolio(survey, llm),
            description="Analyze the user's stock survey and recommend an optimal portfolio."
        ),
        Tool(
            name="stock_chart",
            func=lambda ticker: get_stock_info_and_plot(ticker),
            description="Get stock chart and info by ticker symbol (e.g., 'AAPL', '005930.KS')."
        )
    ]
    if vectorstore:
        tools.append(
            Tool(
                name="market_report_search",
                func=lambda q: rag_search(q, vectorstore, llm),
                description="Search uploaded market analysis documents."
            )
        )

    # Agent ì´ˆê¸°í™”
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    agent = initialize_agent(
        tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True, memory=memory
    )

    # í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œ ë²„íŠ¼ & ê²°ê³¼ ì‹œê°í™”
    st.markdown("#### ğŸ“Š ë‚´ê²Œ ë§ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œ")
    if st.button("í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œë°›ê¸°"):
        with st.spinner("AIê°€ ê°œì¸í™” í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì¶”ì²œ ì¤‘..."):
            try:
                answer = agent.tools[0].func("")  # portfolio_analysis tool ì§ì ‘ í˜¸ì¶œ
                table_md, explanation = extract_markdown_table(answer)
                st.success("ì¶”ì²œ í¬íŠ¸í´ë¦¬ì˜¤ ê²°ê³¼:")
                if explanation:
                    st.markdown(explanation)
                if table_md:
                    st.markdown(table_md)
                    plot_portfolio_pie_from_md(table_md)
            except Exception as e:
                st.error(f"ì¶”ì²œ ì˜¤ë¥˜: {e}")

    # ì±„íŒ… UI
    st.markdown("#### ğŸ’¬ í¬íŠ¸í´ë¦¬ì˜¤/ì‹œì¥/ì£¼ê°€ì— ëŒ€í•´ ììœ ë¡­ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”!")
    if "agentic_msgs" not in st.session_state:
        st.session_state.agentic_msgs = [
            {"role": "assistant", "content": "ì„¤ë¬¸ ì‘ì„± í›„, í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œì„ ë°›ê±°ë‚˜ ììœ ë¡­ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”."}
        ]

    for msg in st.session_state.agentic_msgs:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    user_q = st.chat_input("ì˜ˆ: ì‚¼ì„±ì „ì ì°¨íŠ¸, ì‹œì¥ ì „ë§, ë‚´ í¬íŠ¸í´ë¦¬ì˜¤ ìš”ì•½ ë“±")
    if user_q:
        st.session_state.agentic_msgs.append({"role":"user","content":user_q})
        with st.chat_message("assistant"):
            context = f"ì„¤ë¬¸ ê²°ê³¼:\n{get_portfolio_description(survey)}\nì§ˆë¬¸:\n{user_q}"
            with st.spinner("ì—ì´ì „íŠ¸ê°€ ë‹µë³€ ì¤‘..."):
                try:
                    answer = agent.run(context)
                except Exception as e:
                    answer = f"ì˜¤ë¥˜: {e}"
            st.write(answer)
        st.session_state.agentic_msgs.append({"role":"assistant","content":answer})
